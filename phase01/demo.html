<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Demo: Findings vs No Findings Model &mdash; NM Results Management 1.10 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train" href="train.html" />
    <link rel="prev" title="Overview" href="phase01.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> NM Results Management
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Home</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../home.html">NM Results Management AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#initial-modeling-pre-annotations">Initial Modeling (Pre-Annotations)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-i-regex">Modeling Method I: Regex</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-ii-machine-learning">Modeling Method II: Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-iii-deep-learning">Modeling Method III: Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#data-acquisition">Data Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#initial-model-development">Initial Model Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#clinical-workflow-epic-integration">Clinical Workflow &amp; Epic Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#prospective-clinical-evaluation">Prospective Clinical Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#workflow-challenges">Workflow Challenges</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#updating-the-models">Updating the Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#future-plans">Future Plans</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code.html">Code Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Prerequisites</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Phase 01 Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="phase01.html">Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Demo: Findings vs No Findings Model</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Load-the-Data">Load the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Define-Model-Constants">Define Model Constants</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Tokenize-the-Data-using-a-GloVe-Embedding">Tokenize the Data using a GloVe Embedding</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Define-the-Model">Define the Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Model-Training-Process">Model Training Process</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Evaluate-the-Results">Evaluate the Results</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="classify.html">Classify</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Phase 02 Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../phase02/phase02.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase02/demo_pretrain.html">Demo: Pretraining the NM Results Management Language Model with Custom Corpus</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase02/demo_finetune.html">Demo: Fine-Tuning NM Results Management Language Model with a Custom Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase02/train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase02/classify.html">Classify</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Azure</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../azure.html">Deployment</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NM Results Management</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Demo: Findings vs No Findings Model</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mozzilab/NM_Radiology_AI/blob/main/docs/source/phase01/demo.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Demo:-Findings-vs-No-Findings-Model">
<h1>Demo: Findings vs No Findings Model<a class="headerlink" href="#Demo:-Findings-vs-No-Findings-Model" title="Permalink to this headline"></a></h1>
<p>Phase 01 models—built on Tensorflow- and Keras-backed stacked BiLSTM architectures—follow a similar training scheme that includes:</p>
<ol class="arabic simple">
<li><p>Loading the data</p></li>
<li><p>Defining model constants</p></li>
<li><p>Tokenizing the data using a GloVe embedding</p></li>
<li><p>Defining the model</p></li>
<li><p>Training the model</p></li>
<li><p>Evaluating the results</p></li>
</ol>
<p>This demo aims to provide a notebook with extended annotations for a more in-depth guide for understanding the code using dummy data. However, complete code can be found in <code class="docutils literal notranslate"><span class="pre">/path/to/repo/src/nmrezman/phase01/train/general.py</span></code>. This notebook can be found in <code class="docutils literal notranslate"><span class="pre">/path/to/repo/examples/phase01</span></code>.</p>
<section id="Load-the-Data">
<h2>Load the Data<a class="headerlink" href="#Load-the-Data" title="Permalink to this headline"></a></h2>
<p>Here the data is loaded. During Phase 01 development, preprocessing of the data was done beforehand via the code block below. We preprocessed the notes once, saved off the data, and then trained based off that dataframe. In this example, we employ a similar workflow to best match the source code provided.</p>
<p>Notably, the preprocessing includes (i) lowercasing the report text, (ii) extracting the “impression” / “findings” portion of the report based on the keywords in the report, (iii) removing doctor signatures, and (iv) removing any new lines. This general utility is found via <code class="docutils literal notranslate"><span class="pre">nmrezman.utils.preprocess_input</span></code>. Note, you will likely need to modify this function to best match the formatting of the reports in your hospital network and / or account for extra blank text, new line, etc. introduced by
your system / cloud platform(s).</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">nmrezman</span> <span class="kn">import</span> <span class="n">utils</span>

<span class="n">base_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="s2">&quot;__file__&quot;</span><span class="p">)</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;demo_data.csv&quot;</span><span class="p">))</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="s2">&quot;new_note&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">utils</span><span class="o">.</span><span class="n">preprocess_input</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">is_phase_2</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;demo_data.gz&quot;</span><span class="p">)))</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;demo_data.csv&quot;</span><span class="p">)),</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>

<span class="c1"># Define the path to the data</span>
<span class="n">base_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="s2">&quot;__file__&quot;</span><span class="p">)</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;demo_data.gz&quot;</span><span class="p">))</span>

<span class="c1"># Import data</span>
<span class="c1"># NOTE: this data has already been preprocessed, extracting the findings, removing Dr signature, etc.</span>
<span class="c1"># See `from ..utils import preprocess_input`</span>
<span class="n">modeling_df</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

<span class="c1"># Get preprocessed notes and labels (X and y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;new_note&quot;</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="s2">&quot;No Findings&quot;</span> <span class="k">else</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;selected_finding&quot;</span><span class="p">]]</span>

<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">modeling_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_html</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rpt_num</th>
      <th>note</th>
      <th>selected_finding</th>
      <th>selected_proc</th>
      <th>selected_label</th>
      <th>new_note</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>PROCEDURE:  CT CHEST WO CONTRAST. HISTORY:  Wheezing TECHNIQUE:  Non-contrast helical thoracic CT was performed. COMPARISON:  There is no prior chest CT for comparison. FINDINGS:   Support Devices:  None. Heart/Pericardium/Great Vessels:        Cardiac size is normal.      There is no calcific coronary artery atherosclerosis.       There is no pericardial effusion.      The aorta is normal in diameter.      The main pulmonary artery is normal in diameter. Pleural Spaces:  Few small pleural calcifications are present in the right pleura for example on 2/62 and 3/76.  The pleural spaces are otherwise clear. Mediastinum/Hila:  There is no mediastinal or hilar lymph node enlargement.  Subcentimeter minimally calcified paratracheal lymph nodes are likely related to prior granulomas infection. Neck Base/Chest Wall/Diaphragm/Upper Abdomen:  There is no supraclavicular or axillary lymph node enlargement.  Limited, non-contrast imaging through the upper abdomen is within normal limits.  Mild degenerative change is present in the spine. Lungs/Central Airways: There is a 15 mm nodular density in the nondependent aspect of the bronchus intermedius on 2/52.  The trachea and central airways are otherwise clear.  There is mild diffuse bronchial wall thickening.  There is a calcified granuloma in the posterior right upper lobe.  The lungs are otherwise clear. CONCLUSIONS:   1.  There is mild diffuse bronchial wall thickening suggesting small airways disease such as asthma or bronchitis in the appropriate clinical setting. 2.  A 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  A follow-up CT in 6 months might be considered to evaluate the growth. 3.  Stigmata of old granulomatous disease is present. &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>Lung Findings</td>
      <td>CT Chest</td>
      <td>A 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  A follow-up CT in 6 months might be considered to evaluate the growth.</td>
      <td>support devices:  none. heart/pericardium/great vessels:        cardiac size is normal.      there is no calcific coronary artery atherosclerosis.       there is no pericardial effusion.      the aorta is normal in diameter.      the main pulmonary artery is normal in diameter. pleural spaces:  few small pleural calcifications are present in the right pleura for example on 2/62 and 3/76.  the pleural spaces are otherwise clear. mediastinum/hila:  there is no mediastinal or hilar lymph node enlargement.  subcentimeter minimally calcified paratracheal lymph nodes are likely related to prior granulomas infection. neck base/chest wall/diaphragm/upper abdomen:  there is no supraclavicular or axillary lymph node enlargement.  limited, non-contrast imaging through the upper abdomen is within normal limits.  mild degenerative change is present in the spine. lungs/central airways: there is a 15 mm nodular density in the nondependent aspect of the bronchus intermedius on 2/52.  the trachea and central airways are otherwise clear.  there is mild diffuse bronchial wall thickening.  there is a calcified granuloma in the posterior right upper lobe.  the lungs are otherwise clear. conclusions:   1.  there is mild diffuse bronchial wall thickening suggesting small airways disease such as asthma or bronchitis in the appropriate clinical setting. 2.  a 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  a follow-up ct in 6 months might be considered to evaluate the growth. 3.  stigmata of old granulomatous disease is present.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>PROCEDURE:  CT ABDOMEN PELVIS W CONTRAST COMPARISON:  date INDICATIONS:  Lower abdominal/flank pain on the right TECHNIQUE:     After obtaining the patients consent, CT images were created with intravenous iodinated contrast.  FINDINGS:   LIVER:   The liver is normal in size.  No suspicious liver lesion is seen. The portal and hepatic veins are patent. BILIARY:   No biliary duct dilation. The biliary system is otherwise unremarkable. PANCREAS:   No focal pancreatic lesion.  No pancreatic duct dilation. SPLEEN:   No suspicious splenic lesion is seen. The spleen is normal in size. KIDNEYS:   No suspicious renal lesion is seen.  No hydronephrosis. ADRENALS:   No adrenal gland nodule or thickening.  AORTA/VASCULAR:   No aneurysm. RETROPERITONEUM:   No lymphadenopathy. BOWEL/MESENTERY:   The appendix is normal.  No bowel wall thickening or bowel dilation. ABDOMINAL WALL:   No hernia. URINARY BLADDER:   Incomplete bladder distension limits evaluation, but no focal wall thickening or calculus is seen. PELVIC NODES:   No lymphadenopathy.  PELVIC ORGANS:   Status post hysterectomy.  No pelvic mass. BONES:   No acute fracture or suspicious osseous lesion. LUNG BASES:   No pleural effusion or consolidation. OTHER:   Small hiatal hernia. CONCLUSION:   1.  No acute process is detected. 2.  Small hiatal hernia &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>No Findings</td>
      <td>NaN</td>
      <td>No label</td>
      <td>liver:   the liver is normal in size.  no suspicious liver lesion is seen. the portal and hepatic veins are patent. biliary:   no biliary duct dilation. the biliary system is otherwise unremarkable. pancreas:   no focal pancreatic lesion.  no pancreatic duct dilation. spleen:   no suspicious splenic lesion is seen. the spleen is normal in size. kidneys:   no suspicious renal lesion is seen.  no hydronephrosis. adrenals:   no adrenal gland nodule or thickening.  aorta/vascular:   no aneurysm. retroperitoneum:   no lymphadenopathy. bowel/mesentery:   the appendix is normal.  no bowel wall thickening or bowel dilation. abdominal wall:   no hernia. urinary bladder:   incomplete bladder distension limits evaluation, but no focal wall thickening or calculus is seen. pelvic nodes:   no lymphadenopathy.  pelvic organs:   status post hysterectomy.  no pelvic mass. bones:   no acute fracture or suspicious osseous lesion. lung bases:   no pleural effusion or consolidation. other:   small hiatal hernia. conclusion:   1.  no acute process is detected. 2.  small hiatal hernia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>EXAM:  MRI ABDOMEN W WO CONTRAST CLINICAL INDICATION:  Cirrhosis of liver without ascites, unspecified hepatic cirrhosis type (CMS-HCC) TECHNIQUE: MRI of the abdomen was performed with and without contrast. Multiplanar imaging was performed.  8.5  cc of Gadavist was administered. COMPARISON:  DATE and priors FINDINGS:   On limited views of the lung bases, no acute abnormality is noted. There may be mild distal esophageal wall thickening. On the out of phase series, there is suggestion of some signal gain within the hepatic parenchyma. This is stable. A tiny cystic nonenhancing focus is seen anteriorly in the right hepatic lobe (9/10), unchanged. A subtly micronodular hepatic periphery is noted. There are few subtle hypervascular lesions in the right hepatic lobe, without significant washout. The portal vein is patent. Some splenorenal shunting is redemonstrated, similar to the comparison exam. The spleen measures 12.4 cm in length. No focal splenic lesion is appreciated. There are several small renal lesions again seen, many of which again demonstrate T1 shortening. On the postcontrast subtraction series, no obvious enhancement is noted. The adrenal glands and pancreas are intact. There is mild cholelithiasis, without gallbladder wall thickening or pericholecystic fluid. No free abdominal fluid is visualized. IMPRESSION:   1. Stable cirrhotic appearance of the liver. Few subtly hypervascular hepatic lesions do not demonstrate washout, and probably relate to perfusion variants. No particularly suspicious hepatic mass is seen. 2. Mild splenomegaly to 12.4 cm redemonstrated. Splenorenal shunting is again seen. 3. Scattered simple and complex renal cystic lesions, nonenhancing, stable from March 2040. 4. Incidentally, there is evidence of signal gain in the liver on the out of phase series. This occasionally may represent iron overload.  &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>No Findings</td>
      <td>NaN</td>
      <td>No label</td>
      <td>on limited views of the lung bases, no acute abnormality is noted. there may be mild distal esophageal wall thickening. on the out of phase series, there is suggestion of some signal gain within the hepatic parenchyma. this is stable. a tiny cystic nonenhancing focus is seen anteriorly in the right hepatic lobe (9/10), unchanged. a subtly micronodular hepatic periphery is noted. there are few subtle hypervascular lesions in the right hepatic lobe, without significant washout. the portal vein is patent. some splenorenal shunting is redemonstrated, similar to the comparison exam. the spleen measures 12.4 cm in length. no focal splenic lesion is appreciated. there are several small renal lesions again seen, many of which again demonstrate t1 shortening. on the postcontrast subtraction series, no obvious enhancement is noted. the adrenal glands and pancreas are intact. there is mild cholelithiasis, without gallbladder wall thickening or pericholecystic fluid. no free abdominal fluid is visualized. impression:   1. stable cirrhotic appearance of the liver. few subtly hypervascular hepatic lesions do not demonstrate washout, and probably relate to perfusion variants. no particularly suspicious hepatic mass is seen. 2. mild splenomegaly to 12.4 cm redemonstrated. splenorenal shunting is again seen. 3. scattered simple and complex renal cystic lesions, nonenhancing, stable from march 2040. 4. incidentally, there is evidence of signal gain in the liver on the out of phase series. this occasionally may represent iron overload.</td>
    </tr>
  </tbody>
</table></div>
</div>
</section>
<section id="Define-Model-Constants">
<h2>Define Model Constants<a class="headerlink" href="#Define-Model-Constants" title="Permalink to this headline"></a></h2>
<p>Next, we define some constants that will help parameterize our model. The numbers can be tuned to your specific application. The <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> represents the max length of the reports. In general, we found that the impression section of the NM radiology reports were about ~250 in length, so this was set to <code class="docutils literal notranslate"><span class="pre">300</span></code>. The <code class="docutils literal notranslate"><span class="pre">max_num_words</span></code> represent the max number of words in the vocab to start with. Ultimately, the model will use the actual vocab size for training. Lastly,
<code class="docutils literal notranslate"><span class="pre">glove_embedding_dim</span></code> is the dimension (hyperparameter) of the word embedding as defined by the GloVe word vector. Unless you use one of their other embeddings, this number stays the same; regardless, it should match the downloaded GloVe word vector.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Define model constants</span>
<span class="n">max_sequence_length</span> <span class="o">=</span> <span class="mi">300</span>       <span class="c1"># Max length of report. Avg NM is ~250</span>
<span class="n">max_num_words</span> <span class="o">=</span> <span class="mi">15000</span>           <span class="c1"># Max number of words for vocab</span>
<span class="n">glove_embedding_dim</span> <span class="o">=</span> <span class="mi">300</span>       <span class="c1"># GloVe embedding dimension size</span>
</pre></div>
</div>
</div>
</section>
<section id="Tokenize-the-Data-using-a-GloVe-Embedding">
<h2>Tokenize the Data using a GloVe Embedding<a class="headerlink" href="#Tokenize-the-Data-using-a-GloVe-Embedding" title="Permalink to this headline"></a></h2>
<p>Using a Keras tokenizer object, we define the tokenizer based on the whole text where each word is assigned a unique number and every word is associated with a number. We add basic filtering to remove special characters from getting assigned a value and lowercase all the text to prevent capitalization variations generating new tokens (e.g., “lung” vs “Lung” being assigned different tokens).</p>
<p>Padding is used so that all reports are the same length. In this case, we prepad since we generally found the–for NM reports–the radiology findings and follow-up recommendations were found in the last section of the report. So, if a report is greater than our defined <code class="docutils literal notranslate"><span class="pre">max_sequence_length</span></code> (<code class="docutils literal notranslate"><span class="pre">300</span></code>), it will truncated the text; however, if the report is shorter, the tokenizer will add 0 values (i.e., a placeholder token) at the beginning of the text.</p>
<p>Lastly, we calculate the <code class="docutils literal notranslate"><span class="pre">vocab_size</span></code>–the number of words in the token vector–to give to the model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.preprocessing.text</span> <span class="kn">import</span> <span class="n">Tokenizer</span>
<span class="kn">from</span> <span class="nn">keras.preprocessing.sequence</span> <span class="kn">import</span> <span class="n">pad_sequences</span>

<span class="c1"># Define the tokenizer</span>
<span class="c1"># Lowercase the text; filter out special characters</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">num_words</span><span class="o">=</span><span class="n">max_num_words</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="s1">&#39;!&quot;#$%&amp;()*+,-./:;&lt;=&gt;?@[\]^_`{|}~&#39;</span><span class="p">,</span> <span class="n">lower</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">fit_on_texts</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">word_index</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">word_index</span>
<span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span>

<span class="c1"># Tokenize the notes</span>
<span class="c1"># Prepend since radiology fidings are almost always located in the last section of the report</span>
<span class="n">X_tokenized</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">texts_to_sequences</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">X_tokenized</span> <span class="o">=</span> <span class="n">pad_sequences</span><span class="p">(</span><span class="n">X_tokenized</span><span class="p">,</span> <span class="n">maxlen</span><span class="o">=</span><span class="n">max_sequence_length</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;pre&quot;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Found </span><span class="si">%s</span><span class="s1"> unique tokens.&#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Found 545 unique tokens.
</pre></div></div>
</div>
<p>For setting up GloVe embedding matrix, first we download the 300 dimension GloVe embedding file <code class="docutils literal notranslate"><span class="pre">glove.6B.300d.txt</span></code> (see <a class="reference external" href="https://nlp.stanford.edu/projects/glove/">the GloVe project website</a>). Do this by either manually downloading and extracting the embeddings from the <a class="reference external" href="https://nlp.stanford.edu/data/glove.6B.zip">.zip source</a> into the workspace, or by running the following <code class="docutils literal notranslate"><span class="pre">wget</span></code> command in your cli:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>wget <span class="s2">&quot;https://nlp.stanford.edu/data/glove.6B.zip&quot;</span> -O /tmp/temp.zip
unzip /tmp/temp.zip glove.6B.300d.txt -d /workspace/data
rm /tmp/temp.zip
</pre></div>
</div>
<p>Next, create an embedding vector that will have keys as words present in the GloVe embedding file with its value:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Data path to the pre-downloaded Stanford pretrained word vectors</span>
<span class="c1"># TODO: update this path to your local location of GloVe Stanford pretrained word vectors `glove.6B.300d`</span>
<span class="n">glove_embedding_path</span> <span class="o">=</span> <span class="s2">&quot;/path/to/data/glove.6B.300d.txt&quot;</span>

<span class="c1"># Get GloVe embedding matrix</span>
<span class="c1"># NOTE: Stanford pretrained word vectors glove.6B.300d were downloaded from https://nlp.stanford.edu/projects/glove/</span>
<span class="n">glove_embeddings_index</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">f</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">glove_embedding_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">values</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
    <span class="n">word</span> <span class="o">=</span> <span class="n">values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">coefs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">values</span><span class="p">[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="s2">&quot;float32&quot;</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">pass</span>
    <span class="n">glove_embeddings_index</span><span class="p">[</span><span class="n">word</span><span class="p">]</span> <span class="o">=</span> <span class="n">coefs</span>
<span class="n">f</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">glove_embedding_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">word_index</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">glove_embedding_dim</span><span class="p">))</span>
<span class="k">for</span> <span class="n">word</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">word_index</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">glove_embedding_vector</span> <span class="o">=</span> <span class="n">glove_embeddings_index</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">glove_embedding_vector</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># words not found in embedding index will be all-zeros.</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">glove_embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">glove_embedding_vector</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;could not broadcast input array from shape&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">glove_embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">])),</span>
                    <span class="s2">&quot;into shape&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">glove_embedding_vector</span><span class="p">)),</span> <span class="s2">&quot; Please make sure your&quot;</span>
                                                                <span class="s2">&quot; EMBEDDING_DIM is equal to embedding_vector file ,GloVe,&quot;</span><span class="p">)</span>
                <span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">glove_embedding_matrix</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">glove_embedding_vector</span>
</pre></div>
</div>
</div>
</section>
<section id="Define-the-Model">
<h2>Define the Model<a class="headerlink" href="#Define-the-Model" title="Permalink to this headline"></a></h2>
<p>Next we define the model, which, in this case, is a stacked biLSTM model. We use the Tensorflow and Keras libraries to define this custom model. These layers can be modified as needed.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Embedding</span><span class="p">,</span> <span class="n">SpatialDropout1D</span><span class="p">,</span> <span class="n">Bidirectional</span><span class="p">,</span> <span class="n">LSTM</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.optimizers</span> <span class="kn">import</span> <span class="n">Adam</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span>
                    <span class="n">glove_embedding_dim</span><span class="p">,</span>
                    <span class="n">weights</span><span class="o">=</span><span class="p">[</span><span class="n">glove_embedding_matrix</span><span class="p">],</span>
                    <span class="n">input_length</span><span class="o">=</span><span class="n">max_sequence_length</span><span class="p">,</span>
                    <span class="n">trainable</span><span class="o">=</span><span class="kc">False</span><span class="p">),</span>
<span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">SpatialDropout1D</span><span class="p">(</span><span class="mf">0.25</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">True</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">(</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">200</span><span class="p">)))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.1</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">12</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;softmax&quot;</span><span class="p">))</span>
<span class="n">adam</span> <span class="o">=</span> <span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.0011</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s2">&quot;categorical_crossentropy&quot;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">adam</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">])</span>

<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">(</span><span class="n">expand_nested</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-07 23:48:42.157710: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-07 23:48:42.915489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14635 MB memory:  -&gt; device: 0, name: Tesla V100-PCIE-16GB, pci bus id: 0001:00:00.0, compute capability: 7.0
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Model: &#34;sequential&#34;
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 embedding (Embedding)       (None, 300, 300)          163800

 spatial_dropout1d (SpatialD  (None, 300, 300)         0
 ropout1D)

 bidirectional (Bidirectiona  (None, 300, 400)         801600
 l)

 bidirectional_1 (Bidirectio  (None, 300, 400)         961600
 nal)

 bidirectional_2 (Bidirectio  (None, 400)              961600
 nal)

 dropout (Dropout)           (None, 400)               0

 dense (Dense)               (None, 12)                4812

 dense_1 (Dense)             (None, 2)                 26

=================================================================
Total params: 2,893,438
Trainable params: 2,729,638
Non-trainable params: 163,800
_________________________________________________________________
</pre></div></div>
</div>
</section>
<section id="Model-Training-Process">
<h2>Model Training Process<a class="headerlink" href="#Model-Training-Process" title="Permalink to this headline"></a></h2>
<p>First, we split the data into an 80/20 train and test sets. Note that a different random state is used here (vs the source code) to suit this small sample dataset.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split the data into train and test</span>
<span class="n">train_x</span><span class="p">,</span> <span class="n">valid_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">valid_y</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_tokenized</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.20</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next we define directories and output file names. These locations will be were our final, best trained model live once training is complete. Once trained, these model weights can be used to classify new reports.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_checkpoint_name</span> <span class="o">=</span> <span class="s2">&quot;/path/to/results/phase01/demo/findings/findings_best_model.h5&quot;</span>
<span class="n">result_fname</span> <span class="o">=</span> <span class="s2">&quot;/path/to/results/phase01/demo/findings/findings_best_result.log&quot;</span>

<span class="c1"># Make dirs to save results</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">model_checkpoint_name</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="n">result_fname</span><span class="p">),</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now it’s time to train! Keras does a lot of the heavy lifting here. We add some callbacks to stop early based on if the validation loss continues to decrease. Additionally, we only save the best checkpoint since we only care about saving the model with the best performance. The model will be trained for upwards of 100 epochs.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
<span class="kn">from</span> <span class="nn">tensorflow.keras.utils</span> <span class="kn">import</span> <span class="n">to_categorical</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="kn">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>

<span class="c1"># Clear the Keras backend</span>
<span class="n">K</span><span class="o">.</span><span class="n">clear_session</span><span class="p">()</span>

<span class="c1"># Train!</span>
<span class="n">es</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">15</span><span class="p">,)</span>
<span class="n">mc</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">model_checkpoint_name</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s2">&quot;val_loss&quot;</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">,)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">to_categorical</span><span class="p">(</span><span class="n">train_y</span><span class="p">),</span>
    <span class="n">epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">es</span><span class="p">,</span> <span class="n">mc</span><span class="p">],</span>
    <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span> <span class="n">to_categorical</span><span class="p">(</span><span class="n">valid_y</span><span class="p">)),</span>
<span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 1/30
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-03-07 23:48:52.718937: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1/1 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.6250
Epoch 00001: val_loss improved from inf to 0.78142, saving model to /path/to/results/phase01/demo/findings/findings_best_model.h5
1/1 [==============================] - 11s 11s/step - loss: 0.6717 - accuracy: 0.6250 - val_loss: 0.7814 - val_accuracy: 0.3333
Epoch 2/30
1/1 [==============================] - ETA: 0s - loss: 0.5393 - accuracy: 0.7500
Epoch 00002: val_loss did not improve from 0.78142
1/1 [==============================] - 0s 127ms/step - loss: 0.5393 - accuracy: 0.7500 - val_loss: 0.9052 - val_accuracy: 0.6667
Epoch 3/30
1/1 [==============================] - ETA: 0s - loss: 0.7345 - accuracy: 0.6250
Epoch 00003: val_loss did not improve from 0.78142
1/1 [==============================] - 0s 123ms/step - loss: 0.7345 - accuracy: 0.6250 - val_loss: 0.9365 - val_accuracy: 0.3333
Epoch 4/30
1/1 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.7500
Epoch 00004: val_loss did not improve from 0.78142
1/1 [==============================] - 0s 116ms/step - loss: 0.3943 - accuracy: 0.7500 - val_loss: 0.9092 - val_accuracy: 0.3333
Epoch 5/30
1/1 [==============================] - ETA: 0s - loss: 0.4060 - accuracy: 0.7500
Epoch 00005: val_loss improved from 0.78142 to 0.53731, saving model to /path/to/results/phase01/demo/findings/findings_best_model.h5
1/1 [==============================] - 0s 245ms/step - loss: 0.4060 - accuracy: 0.7500 - val_loss: 0.5373 - val_accuracy: 0.6667
Epoch 6/30
1/1 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 1.0000
Epoch 00006: val_loss did not improve from 0.53731
1/1 [==============================] - 0s 116ms/step - loss: 0.2056 - accuracy: 1.0000 - val_loss: 0.6331 - val_accuracy: 0.6667
Epoch 7/30
1/1 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.8750
Epoch 00007: val_loss improved from 0.53731 to 0.42821, saving model to /path/to/results/phase01/demo/findings/findings_best_model.h5
1/1 [==============================] - 0s 219ms/step - loss: 0.2440 - accuracy: 0.8750 - val_loss: 0.4282 - val_accuracy: 0.6667
Epoch 8/30
1/1 [==============================] - ETA: 0s - loss: 0.0470 - accuracy: 1.0000
Epoch 00008: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 113ms/step - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.5175 - val_accuracy: 0.6667
Epoch 9/30
1/1 [==============================] - ETA: 0s - loss: 0.0264 - accuracy: 1.0000
Epoch 00009: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 117ms/step - loss: 0.0264 - accuracy: 1.0000 - val_loss: 1.1193 - val_accuracy: 0.6667
Epoch 10/30
1/1 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 1.0000
Epoch 00010: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 116ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.3333
Epoch 11/30
1/1 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 1.0000
Epoch 00011: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 111ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5533 - val_accuracy: 0.3333
Epoch 12/30
1/1 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 1.0000
Epoch 00012: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 114ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5892 - val_accuracy: 0.6667
Epoch 13/30
1/1 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 1.0000
Epoch 00013: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 114ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.6667
Epoch 14/30
1/1 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 1.0000
Epoch 00014: val_loss did not improve from 0.42821
1/1 [==============================] - 0s 118ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.7344 - val_accuracy: 0.6667
Epoch 15/30
1/1 [==============================] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000
Epoch 00015: val_loss improved from 0.42821 to 0.29115, saving model to /path/to/results/phase01/demo/findings/findings_best_model.h5
1/1 [==============================] - 0s 229ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2912 - val_accuracy: 0.6667
Epoch 16/30
1/1 [==============================] - ETA: 0s - loss: 7.6486e-04 - accuracy: 1.0000
Epoch 00016: val_loss improved from 0.29115 to 0.12271, saving model to /path/to/results/phase01/demo/findings/findings_best_model.h5
1/1 [==============================] - 0s 221ms/step - loss: 7.6486e-04 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 1.0000
Epoch 17/30
1/1 [==============================] - ETA: 0s - loss: 5.9440e-04 - accuracy: 1.0000
Epoch 00017: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 113ms/step - loss: 5.9440e-04 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.6667
Epoch 18/30
1/1 [==============================] - ETA: 0s - loss: 6.6654e-04 - accuracy: 1.0000
Epoch 00018: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 118ms/step - loss: 6.6654e-04 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.6667
Epoch 19/30
1/1 [==============================] - ETA: 0s - loss: 3.7514e-04 - accuracy: 1.0000
Epoch 00019: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 117ms/step - loss: 3.7514e-04 - accuracy: 1.0000 - val_loss: 1.4473 - val_accuracy: 0.6667
Epoch 20/30
1/1 [==============================] - ETA: 0s - loss: 3.6986e-04 - accuracy: 1.0000
Epoch 00020: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 115ms/step - loss: 3.6986e-04 - accuracy: 1.0000 - val_loss: 1.8139 - val_accuracy: 0.6667
Epoch 21/30
1/1 [==============================] - ETA: 0s - loss: 3.2677e-04 - accuracy: 1.0000
Epoch 00021: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 117ms/step - loss: 3.2677e-04 - accuracy: 1.0000 - val_loss: 2.0806 - val_accuracy: 0.6667
Epoch 22/30
1/1 [==============================] - ETA: 0s - loss: 2.0694e-04 - accuracy: 1.0000
Epoch 00022: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 118ms/step - loss: 2.0694e-04 - accuracy: 1.0000 - val_loss: 2.2770 - val_accuracy: 0.6667
Epoch 23/30
1/1 [==============================] - ETA: 0s - loss: 1.7372e-04 - accuracy: 1.0000
Epoch 00023: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 122ms/step - loss: 1.7372e-04 - accuracy: 1.0000 - val_loss: 2.4248 - val_accuracy: 0.6667
Epoch 24/30
1/1 [==============================] - ETA: 0s - loss: 1.7007e-04 - accuracy: 1.0000
Epoch 00024: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 117ms/step - loss: 1.7007e-04 - accuracy: 1.0000 - val_loss: 2.5394 - val_accuracy: 0.6667
Epoch 25/30
1/1 [==============================] - ETA: 0s - loss: 1.7452e-04 - accuracy: 1.0000
Epoch 00025: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 112ms/step - loss: 1.7452e-04 - accuracy: 1.0000 - val_loss: 2.6312 - val_accuracy: 0.6667
Epoch 26/30
1/1 [==============================] - ETA: 0s - loss: 1.3593e-04 - accuracy: 1.0000
Epoch 00026: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 115ms/step - loss: 1.3593e-04 - accuracy: 1.0000 - val_loss: 2.7067 - val_accuracy: 0.6667
Epoch 27/30
1/1 [==============================] - ETA: 0s - loss: 1.3290e-04 - accuracy: 1.0000
Epoch 00027: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 115ms/step - loss: 1.3290e-04 - accuracy: 1.0000 - val_loss: 2.7706 - val_accuracy: 0.6667
Epoch 28/30
1/1 [==============================] - ETA: 0s - loss: 9.7877e-05 - accuracy: 1.0000
Epoch 00028: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 114ms/step - loss: 9.7877e-05 - accuracy: 1.0000 - val_loss: 2.8258 - val_accuracy: 0.6667
Epoch 29/30
1/1 [==============================] - ETA: 0s - loss: 9.9574e-05 - accuracy: 1.0000
Epoch 00029: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 117ms/step - loss: 9.9574e-05 - accuracy: 1.0000 - val_loss: 2.8743 - val_accuracy: 0.6667
Epoch 30/30
1/1 [==============================] - ETA: 0s - loss: 6.7379e-05 - accuracy: 1.0000
Epoch 00030: val_loss did not improve from 0.12271
1/1 [==============================] - 0s 113ms/step - loss: 6.7379e-05 - accuracy: 1.0000 - val_loss: 2.9174 - val_accuracy: 0.6667
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;keras.callbacks.History at 0x7f4c14f29370&gt;
</pre></div></div>
</div>
</section>
<section id="Evaluate-the-Results">
<h2>Evaluate the Results<a class="headerlink" href="#Evaluate-the-Results" title="Permalink to this headline"></a></h2>
<p>Using <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>’s <code class="docutils literal notranslate"><span class="pre">classification_report</span></code> and <code class="docutils literal notranslate"><span class="pre">confusion_matrix</span></code>, we can evaluate how well the model performs on the test dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># Load in the best model</span>
<span class="n">best_model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="n">model_checkpoint_name</span><span class="p">)</span>

<span class="c1"># Perform confusion matrix and save the results</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_x</span><span class="p">))</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">report</span> <span class="o">=</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">valid_y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">matrix</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">valid_y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">result_fname</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fh</span><span class="p">:</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Classification Report:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">report</span><span class="p">)</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">Confusion Matrix:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">fh</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array2string</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">separator</span><span class="o">=</span><span class="s2">&quot;, &quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         1

    accuracy                           1.00         3
   macro avg       1.00      1.00      1.00         3
weighted avg       1.00      1.00      1.00         3

[[2 0]
 [0 1]]
</pre></div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="phase01.html" class="btn btn-neutral float-left" title="Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="train.html" class="btn btn-neutral float-right" title="Train" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NM HIT.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>