<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Demo: Pretraining the NM Results Management Language Model with Custom Corpus &mdash; NM Results Management 1.10 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-bootstrap.5fd3999ee7762ccc51105388f4a9d115.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" type="text/css" />
      <link rel="stylesheet" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Demo: Fine-Tuning NM Results Management Language Model with a Custom Dataset" href="demo_finetune.html" />
    <link rel="prev" title="Overview" href="phase02.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> NM Results Management
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Home</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../home.html">NM Results Management AI</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Project Overview</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">Intro</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#initial-modeling-pre-annotations">Initial Modeling (Pre-Annotations)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-i-regex">Modeling Method I: Regex</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-ii-machine-learning">Modeling Method II: Machine Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#modeling-method-iii-deep-learning">Modeling Method III: Deep Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#data-acquisition">Data Acquisition</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#initial-model-development">Initial Model Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#clinical-workflow-epic-integration">Clinical Workflow &amp; Epic Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#prospective-clinical-evaluation">Prospective Clinical Evaluation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#workflow-challenges">Workflow Challenges</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#updating-the-models">Updating the Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../about.html#future-plans">Future Plans</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../code.html">Code Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../start.html">Prerequisites</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Phase 01 Models</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../phase01/phase01.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase01/demo.html">Demo: Findings vs No Findings Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase01/train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="../phase01/classify.html">Classify</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Phase 02 Models</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="phase02.html">Overview</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Demo: Pretraining the NM Results Management Language Model with Custom Corpus</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Load-the-Data">Load the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Preprocess-the-Data">Preprocess the Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Tokenize-the-Datasets">Tokenize the Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Pretrain-the-Model">Pretrain the Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="demo_finetune.html">Demo: Fine-Tuning NM Results Management Language Model with a Custom Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="train.html">Train</a></li>
<li class="toctree-l1"><a class="reference internal" href="classify.html">Classify</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Azure</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../azure.html">Deployment</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">NM Results Management</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
      <li>Demo: Pretraining the NM Results Management Language Model with Custom Corpus</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/mozzilab/NM_Radiology_AI/blob/main/docs/source/phase02/demo_pretrain.ipynb" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<section id="Demo:-Pretraining-the-NM-Results-Management-Language-Model-with-Custom-Corpus">
<h1>Demo: Pretraining the NM Results Management Language Model with Custom Corpus<a class="headerlink" href="#Demo:-Pretraining-the-NM-Results-Management-Language-Model-with-Custom-Corpus" title="Permalink to this headline"></a></h1>
<p>For Masked Language Modeling (MLM), we randomly mask some tokens by replacing them by <code class="docutils literal notranslate"><span class="pre">[MASK]</span></code>, and then the labels are adjusted to only include masked tokens. In this example, we use a sample of ten radiology reports to pretrain from an initial RoBERTa checkpoint.</p>
<section id="Load-the-Data">
<h2>Load the Data<a class="headerlink" href="#Load-the-Data" title="Permalink to this headline"></a></h2>
<p>First, the data is loaded. For pretraining, we are only concerned with the radiology report. We will pretrain the model to predict masked words in the report.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">joblib</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>

<span class="c1"># Define the path to the data</span>
<span class="n">base_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="s2">&quot;__file__&quot;</span><span class="p">)</span>
<span class="n">data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_path</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">,</span> <span class="s2">&quot;demo_data.gz&quot;</span><span class="p">))</span>

<span class="c1"># Import data</span>
<span class="n">modeling_df</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">data_path</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">modeling_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to_html</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>rpt_num</th>
      <th>note</th>
      <th>selected_finding</th>
      <th>selected_proc</th>
      <th>selected_label</th>
      <th>new_note</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>PROCEDURE:  CT CHEST WO CONTRAST. HISTORY:  Wheezing TECHNIQUE:  Non-contrast helical thoracic CT was performed. COMPARISON:  There is no prior chest CT for comparison. FINDINGS:   Support Devices:  None. Heart/Pericardium/Great Vessels:        Cardiac size is normal.      There is no calcific coronary artery atherosclerosis.       There is no pericardial effusion.      The aorta is normal in diameter.      The main pulmonary artery is normal in diameter. Pleural Spaces:  Few small pleural calcifications are present in the right pleura for example on 2/62 and 3/76.  The pleural spaces are otherwise clear. Mediastinum/Hila:  There is no mediastinal or hilar lymph node enlargement.  Subcentimeter minimally calcified paratracheal lymph nodes are likely related to prior granulomas infection. Neck Base/Chest Wall/Diaphragm/Upper Abdomen:  There is no supraclavicular or axillary lymph node enlargement.  Limited, non-contrast imaging through the upper abdomen is within normal limits.  Mild degenerative change is present in the spine. Lungs/Central Airways: There is a 15 mm nodular density in the nondependent aspect of the bronchus intermedius on 2/52.  The trachea and central airways are otherwise clear.  There is mild diffuse bronchial wall thickening.  There is a calcified granuloma in the posterior right upper lobe.  The lungs are otherwise clear. CONCLUSIONS:   1.  There is mild diffuse bronchial wall thickening suggesting small airways disease such as asthma or bronchitis in the appropriate clinical setting. 2.  A 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  A follow-up CT in 6 months might be considered to evaluate the growth. 3.  Stigmata of old granulomatous disease is present. &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>Lung Findings</td>
      <td>CT Chest</td>
      <td>A 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  A follow-up CT in 6 months might be considered to evaluate the growth.</td>
      <td>support devices:  none. heart/pericardium/great vessels:        cardiac size is normal.      there is no calcific coronary artery atherosclerosis.       there is no pericardial effusion.      the aorta is normal in diameter.      the main pulmonary artery is normal in diameter. pleural spaces:  few small pleural calcifications are present in the right pleura for example on 2/62 and 3/76.  the pleural spaces are otherwise clear. mediastinum/hila:  there is no mediastinal or hilar lymph node enlargement.  subcentimeter minimally calcified paratracheal lymph nodes are likely related to prior granulomas infection. neck base/chest wall/diaphragm/upper abdomen:  there is no supraclavicular or axillary lymph node enlargement.  limited, non-contrast imaging through the upper abdomen is within normal limits.  mild degenerative change is present in the spine. lungs/central airways: there is a 15 mm nodular density in the nondependent aspect of the bronchus intermedius on 2/52.  the trachea and central airways are otherwise clear.  there is mild diffuse bronchial wall thickening.  there is a calcified granuloma in the posterior right upper lobe.  the lungs are otherwise clear. conclusions:   1.  there is mild diffuse bronchial wall thickening suggesting small airways disease such as asthma or bronchitis in the appropriate clinical setting. 2.  a 3 mm nodular soft tissue attenuation in the nondependent aspect of the right bronchus intermedius is nonspecific, which could be mucus or abnormal soft tissue.  a follow-up ct in 6 months might be considered to evaluate the growth. 3.  stigmata of old granulomatous disease is present.</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>PROCEDURE:  CT ABDOMEN PELVIS W CONTRAST COMPARISON:  date INDICATIONS:  Lower abdominal/flank pain on the right TECHNIQUE:     After obtaining the patients consent, CT images were created with intravenous iodinated contrast.  FINDINGS:   LIVER:   The liver is normal in size.  No suspicious liver lesion is seen. The portal and hepatic veins are patent. BILIARY:   No biliary duct dilation. The biliary system is otherwise unremarkable. PANCREAS:   No focal pancreatic lesion.  No pancreatic duct dilation. SPLEEN:   No suspicious splenic lesion is seen. The spleen is normal in size. KIDNEYS:   No suspicious renal lesion is seen.  No hydronephrosis. ADRENALS:   No adrenal gland nodule or thickening.  AORTA/VASCULAR:   No aneurysm. RETROPERITONEUM:   No lymphadenopathy. BOWEL/MESENTERY:   The appendix is normal.  No bowel wall thickening or bowel dilation. ABDOMINAL WALL:   No hernia. URINARY BLADDER:   Incomplete bladder distension limits evaluation, but no focal wall thickening or calculus is seen. PELVIC NODES:   No lymphadenopathy.  PELVIC ORGANS:   Status post hysterectomy.  No pelvic mass. BONES:   No acute fracture or suspicious osseous lesion. LUNG BASES:   No pleural effusion or consolidation. OTHER:   Small hiatal hernia. CONCLUSION:   1.  No acute process is detected. 2.  Small hiatal hernia &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>No Findings</td>
      <td>NaN</td>
      <td>No label</td>
      <td>liver:   the liver is normal in size.  no suspicious liver lesion is seen. the portal and hepatic veins are patent. biliary:   no biliary duct dilation. the biliary system is otherwise unremarkable. pancreas:   no focal pancreatic lesion.  no pancreatic duct dilation. spleen:   no suspicious splenic lesion is seen. the spleen is normal in size. kidneys:   no suspicious renal lesion is seen.  no hydronephrosis. adrenals:   no adrenal gland nodule or thickening.  aorta/vascular:   no aneurysm. retroperitoneum:   no lymphadenopathy. bowel/mesentery:   the appendix is normal.  no bowel wall thickening or bowel dilation. abdominal wall:   no hernia. urinary bladder:   incomplete bladder distension limits evaluation, but no focal wall thickening or calculus is seen. pelvic nodes:   no lymphadenopathy.  pelvic organs:   status post hysterectomy.  no pelvic mass. bones:   no acute fracture or suspicious osseous lesion. lung bases:   no pleural effusion or consolidation. other:   small hiatal hernia. conclusion:   1.  no acute process is detected. 2.  small hiatal hernia</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>EXAM:  MRI ABDOMEN W WO CONTRAST CLINICAL INDICATION:  Cirrhosis of liver without ascites, unspecified hepatic cirrhosis type (CMS-HCC) TECHNIQUE: MRI of the abdomen was performed with and without contrast. Multiplanar imaging was performed.  8.5  cc of Gadavist was administered. COMPARISON:  DATE and priors FINDINGS:   On limited views of the lung bases, no acute abnormality is noted. There may be mild distal esophageal wall thickening. On the out of phase series, there is suggestion of some signal gain within the hepatic parenchyma. This is stable. A tiny cystic nonenhancing focus is seen anteriorly in the right hepatic lobe (9/10), unchanged. A subtly micronodular hepatic periphery is noted. There are few subtle hypervascular lesions in the right hepatic lobe, without significant washout. The portal vein is patent. Some splenorenal shunting is redemonstrated, similar to the comparison exam. The spleen measures 12.4 cm in length. No focal splenic lesion is appreciated. There are several small renal lesions again seen, many of which again demonstrate T1 shortening. On the postcontrast subtraction series, no obvious enhancement is noted. The adrenal glands and pancreas are intact. There is mild cholelithiasis, without gallbladder wall thickening or pericholecystic fluid. No free abdominal fluid is visualized. IMPRESSION:   1. Stable cirrhotic appearance of the liver. Few subtly hypervascular hepatic lesions do not demonstrate washout, and probably relate to perfusion variants. No particularly suspicious hepatic mass is seen. 2. Mild splenomegaly to 12.4 cm redemonstrated. Splenorenal shunting is again seen. 3. Scattered simple and complex renal cystic lesions, nonenhancing, stable from March 2040. 4. Incidentally, there is evidence of signal gain in the liver on the out of phase series. This occasionally may represent iron overload.  &amp;#x20; FINAL REPORT Attending Radiologist:</td>
      <td>No Findings</td>
      <td>NaN</td>
      <td>No label</td>
      <td>on limited views of the lung bases, no acute abnormality is noted. there may be mild distal esophageal wall thickening. on the out of phase series, there is suggestion of some signal gain within the hepatic parenchyma. this is stable. a tiny cystic nonenhancing focus is seen anteriorly in the right hepatic lobe (9/10), unchanged. a subtly micronodular hepatic periphery is noted. there are few subtle hypervascular lesions in the right hepatic lobe, without significant washout. the portal vein is patent. some splenorenal shunting is redemonstrated, similar to the comparison exam. the spleen measures 12.4 cm in length. no focal splenic lesion is appreciated. there are several small renal lesions again seen, many of which again demonstrate t1 shortening. on the postcontrast subtraction series, no obvious enhancement is noted. the adrenal glands and pancreas are intact. there is mild cholelithiasis, without gallbladder wall thickening or pericholecystic fluid. no free abdominal fluid is visualized. impression:   1. stable cirrhotic appearance of the liver. few subtly hypervascular hepatic lesions do not demonstrate washout, and probably relate to perfusion variants. no particularly suspicious hepatic mass is seen. 2. mild splenomegaly to 12.4 cm redemonstrated. splenorenal shunting is again seen. 3. scattered simple and complex renal cystic lesions, nonenhancing, stable from march 2040. 4. incidentally, there is evidence of signal gain in the liver on the out of phase series. this occasionally may represent iron overload.</td>
    </tr>
  </tbody>
</table></div>
</div>
</section>
<section id="Preprocess-the-Data">
<h2>Preprocess the Data<a class="headerlink" href="#Preprocess-the-Data" title="Permalink to this headline"></a></h2>
<p>First, the impression (i.e., the findings / conclusions section) of the report is extracted, any doctor signatures are removed, and the report lowercased. This preprocessing section may need to be modified to accommodate your healthcare system’s reports, formatting, etc. The <code class="docutils literal notranslate"><span class="pre">preprocess_note</span></code> function is modified from <code class="docutils literal notranslate"><span class="pre">nmrezman.utils.preprocess_input</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">keyword_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">keywords</span><span class="p">,</span> <span class="n">return_idx</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extract portion of string given a list of possible delimiters (keywords) via partition method</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">for</span> <span class="n">keyword</span> <span class="ow">in</span> <span class="n">keywords</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">keyword</span><span class="p">)[</span><span class="mi">2</span><span class="p">]</span> <span class="o">!=</span><span class="s1">&#39;&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">partition</span><span class="p">(</span><span class="n">keyword</span><span class="p">)[</span><span class="n">return_idx</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">x</span>

<span class="k">def</span> <span class="nf">preprocess_note</span><span class="p">(</span><span class="n">note</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Get the impression from the note, remove doctor signature, and lowercase</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">impression_keywords</span> <span class="o">=</span> <span class="p">[</span>
            <span class="s2">&quot;impression:&quot;</span><span class="p">,</span>
            <span class="s2">&quot;conclusion(s):&quot;</span><span class="p">,</span>
            <span class="s2">&quot;conclusions:&quot;</span><span class="p">,</span>
            <span class="s2">&quot;conclusion:&quot;</span><span class="p">,</span>
            <span class="s2">&quot;finding:&quot;</span><span class="p">,</span>
            <span class="s2">&quot;findings:&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">signature_keywords</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;&amp;#x20&quot;</span><span class="p">,</span>
        <span class="s2">&quot;final report attending radiologist:&quot;</span><span class="p">,</span>
    <span class="p">]</span>
    <span class="n">impressions</span> <span class="o">=</span> <span class="n">keyword_split</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">note</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">(),</span> <span class="n">impression_keywords</span><span class="p">)</span>
    <span class="n">impressions</span> <span class="o">=</span> <span class="n">keyword_split</span><span class="p">(</span><span class="n">note</span><span class="p">,</span> <span class="n">signature_keywords</span><span class="p">,</span> <span class="n">return_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">impressions</span>

<span class="c1"># Preprocess the note</span>
<span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;note&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocess_note</span><span class="p">)</span>
<span class="n">modeling_df</span> <span class="o">=</span> <span class="n">modeling_df</span><span class="p">[</span><span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">notnull</span><span class="p">()]</span>
<span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">modeling_df</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span> <span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Next, the dataset is split into train and test sets, reserving 20% for the test set.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Split into train and test data</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">modeling_df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">7867</span><span class="p">)</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span>
</pre></div>
</div>
</div>
<p>The data is then put into 🤗 <code class="docutils literal notranslate"><span class="pre">Datasets</span></code> to be used with the 🤗 <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>. This allows the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> function to extract data and labels from easily.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DatasetDict</span>

<span class="c1"># Import the data into a dataset</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_frame</span><span class="p">())</span>
<span class="n">test_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_pandas</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">to_frame</span><span class="p">())</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">DatasetDict</span><span class="p">({</span><span class="s2">&quot;train&quot;</span><span class="p">:</span> <span class="n">train_dataset</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span> <span class="n">test_dataset</span><span class="p">})</span>
</pre></div>
</div>
</div>
</section>
<section id="Tokenize-the-Datasets">
<h2>Tokenize the Datasets<a class="headerlink" href="#Tokenize-the-Datasets" title="Permalink to this headline"></a></h2>
<p>First, we define a tokenizer to mask words or word fragments to tokens. Here, we are using <a class="reference external" href="https://huggingface.co/roberta-base">🤗’s pretrained RoBERTa base model’s</a> checkpoint. Padding is done on the left side since NM radiology reports generally have the findings at the end of the report. Note that you can change out the tokenizer and model to start from a different RoBERTa checkpoint (e.g., <code class="docutils literal notranslate"><span class="pre">roberta-large</span></code>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="c1"># Specify the model checkpoint for tokenizing and get tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="s2">&quot;distilroberta-base&quot;</span><span class="p">,</span>
        <span class="n">use_fast</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">tokenized_dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="k">lambda</span> <span class="n">examples</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">],</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_proc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">remove_columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;impression&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ea6a8cee228e407d9d63e70430ae36ec", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "cfe785cdaa17404c933458f6c2e44921", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>We group texts together and chunk them in samples of length <code class="docutils literal notranslate"><span class="pre">block_size</span></code>. We use a <code class="docutils literal notranslate"><span class="pre">block_size</span></code> of <code class="docutils literal notranslate"><span class="pre">128</span></code>, but you can adjust this to your needs. Further, you can skip that step if your dataset is composed of individual sentences. This is ultimately the dataset we will use for training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">group_texts</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="c1"># Sample chunked into size `block_size`</span>
    <span class="n">block_size</span> <span class="o">=</span> <span class="mi">128</span>

    <span class="c1"># Concatenate all texts</span>
    <span class="n">concatenated_examples</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="p">[])</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>
    <span class="n">total_length</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">concatenated_examples</span><span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">examples</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="mi">0</span><span class="p">]])</span>

    <span class="c1"># We drop the small remainder. We could add padding if the model supported it rather than dropping it.</span>
    <span class="c1"># This represents the maximum length based on the block size</span>
    <span class="c1"># You can customize this part to your needs.</span>
    <span class="n">max_length</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_length</span> <span class="o">//</span> <span class="n">block_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">block_size</span>
    <span class="n">result</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="p">[</span><span class="n">t</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_length</span><span class="p">,</span> <span class="n">block_size</span><span class="p">)]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">concatenated_examples</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
    <span class="n">result</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">result</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="c1"># Group the text into chunks to get &quot;sentence-like&quot; data structure</span>
<span class="n">lm_dataset</span> <span class="o">=</span> <span class="n">tokenized_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span>
    <span class="n">group_texts</span><span class="p">,</span>
    <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">num_proc</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "643e1bc9efe44a27a93023c26f658f0f", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "722855a8f99c42848140a4b30395d219", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="Pretrain-the-Model">
<h2>Pretrain the Model<a class="headerlink" href="#Pretrain-the-Model" title="Permalink to this headline"></a></h2>
<p>The <code class="docutils literal notranslate"><span class="pre">data_collator</span></code> is a function that is responsible of taking the samples and batching them in tensors. Here we want to do the random-masking. We could do it as a pre-processing step (like we do for tokenization), but then the tokens would always be masked the same way at each epoch. By doing this step inside the <code class="docutils literal notranslate"><span class="pre">data_collator</span></code>, we ensure this random masking is done in a new way each time we go over the data.</p>
<p>To do this masking for us, 🤗 provides a <code class="docutils literal notranslate"><span class="pre">DataCollatorForLanguageModeling</span></code> (see their <a class="reference external" href="https://huggingface.co/docs/transformers/v4.15.0/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling">docs</a>). We can adjust the probability of the masking; here we have chosen a probability of 15%.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorForLanguageModeling</span>

<span class="c1"># Define a data collator to accomplish random masking</span>
<span class="c1"># By doing this step in the `data_collator` (vs as a pre-processing step like we do for tokenization),</span>
<span class="c1"># we ensure random masking is done in a new way each time we go over the data (i.e., per epoch)</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorForLanguageModeling</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">mlm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">mlm_probability</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>Here we define the model checkpoint from which we will start training and then begin training using the 🤗 <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>, which will train according to the parameters specified in the 🤗 <code class="docutils literal notranslate"><span class="pre">TrainingArguments</span></code>. 🤗 will take care of all the training for us! When done, the last checkpoint will be used as the starting checkpoint for fine-tuning the Lung, Adrenal, or No Findings model and Lung Recommended Procedure model.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForMaskedLM</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span><span class="p">,</span> <span class="n">TrainingArguments</span>

<span class="c1"># Define the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForMaskedLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;distilroberta-base&quot;</span><span class="p">)</span>

<span class="c1"># Define the training parameters and 🤗 Trainer</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
    <span class="n">output_dir</span><span class="o">=</span><span class="s2">&quot;/path/to/results/phase02/demo&quot;</span><span class="p">,</span>
    <span class="n">overwrite_output_dir</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
    <span class="n">save_steps</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">report_to</span><span class="o">=</span><span class="s2">&quot;none&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">lm_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">lm_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Train!</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
***** Running training *****
  Num examples = 32
  Num Epochs = 4
  Instantaneous batch size per device = 32
  Total train batch size (w. parallel, distributed &amp; accumulation) = 32
  Gradient Accumulation steps = 1
  Total optimization steps = 4
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
    <div>

      <progress value='4' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>
      [4/4 00:11, Epoch 4/4]
    </div>
    <table border="1" class="dataframe">
  <thead>
 <tr style="text-align: left;">
      <th>Epoch</th>
      <th>Training Loss</th>
      <th>Validation Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>No log</td>
      <td>2.598713</td>
    </tr>
    <tr>
      <td>2</td>
      <td>No log</td>
      <td>2.722490</td>
    </tr>
    <tr>
      <td>3</td>
      <td>No log</td>
      <td>3.001497</td>
    </tr>
    <tr>
      <td>4</td>
      <td>No log</td>
      <td>2.590591</td>
    </tr>
  </tbody>
</table><p></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
***** Running Evaluation *****
  Num examples = 12
  Batch size = 8
Saving model checkpoint to /path/to/results/phase02/demo/checkpoint-2
Configuration saved in /path/to/results/phase02/demo/checkpoint-2/config.json
Model weights saved in /path/to/results/phase02/demo/checkpoint-2/pytorch_model.bin
Deleting older checkpoint [/path/to/results/phase02/demo/checkpoint-2] due to args.save_total_limit
***** Running Evaluation *****
  Num examples = 12
  Batch size = 8
***** Running Evaluation *****
  Num examples = 12
  Batch size = 8
Saving model checkpoint to /path/to/results/phase02/demo/checkpoint-4
Configuration saved in /path/to/results/phase02/demo/checkpoint-4/config.json
Model weights saved in /path/to/results/phase02/demo/checkpoint-4/pytorch_model.bin
***** Running Evaluation *****
  Num examples = 12
  Batch size = 8


Training completed. Do not forget to share your model on huggingface.co/models =)


</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
TrainOutput(global_step=4, training_loss=3.0825986862182617, metrics={&#39;train_runtime&#39;: 11.9044, &#39;train_samples_per_second&#39;: 10.752, &#39;train_steps_per_second&#39;: 0.336, &#39;total_flos&#39;: 4243897810944.0, &#39;train_loss&#39;: 3.0825986862182617, &#39;epoch&#39;: 4.0})
</pre></div></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="phase02.html" class="btn btn-neutral float-left" title="Overview" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="demo_finetune.html" class="btn btn-neutral float-right" title="Demo: Fine-Tuning NM Results Management Language Model with a Custom Dataset" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NM HIT.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>